/*import the libraries*/
from bs4 import BeautifulSoup
import requests
import pandas as pd
import csv

/*pull the url to scrape*/
url = "https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue"
page=requests.get(url)
soup = BeautifulSoup(page.text, 'html')
print(soup.prettify())

/*use find and find_all to find specific tags from HTML or XML that we need to scrape*/
soup.find('table')
soup.find('table',class_="wikitable sortable")
table=soup.find_all('table')[1]
print(table)
world_titles=table.find_all('th')

/*print the table headers as the column names*/
world_table_titles = [title.text.strip() for title in world_titles]
print(world_table_titles)

/*then we use pandas to create dataframes*/
df=pd.DataFrame(columns = world_table_titles)
column_data = table.find_all('tr')
for row in column_data[1:]:
    row_data = row.find_all('td')
    each_row_data = [data.text.strip() for data in row_data]
    length = len (df) 
    df.loc [length] = each_row_data

/*then we can save it in our system in any format (in this its csv.)*/
df.to_csv('D:/Python/miniproj_alex.csv', index = False)
