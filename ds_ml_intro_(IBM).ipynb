{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8cb3a7f-e945-48f2-87ee-c4c613bc5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b0ea85d2-b362-4dd7-9dbc-097ec15ca96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (80, 5) (80,)\n",
      "Testing set shape:  (20, 5) (20,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_samples = 100\n",
    "num_features = 5\n",
    "x = np.random.rand(num_samples, num_features)\n",
    "y = np.random.randint(0, 2, size = num_samples)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"Training set shape: \", x_train.shape, y_train.shape)\n",
    "print(\"Testing set shape: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32a0ea21-f2ef-4520-86c2-008435904377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[20  3]\n",
      " [13  4]]\n",
      "Accuracy:  0.6\n",
      "Precision:  0.5714285714285714\n",
      "Recall:  0.23529411764705882\n",
      "Specificity:  0.8695652173913043\n",
      "F1 Score:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x = np.random.rand(200, 4)\n",
    "y = np.random.randint(0, 2, size = 200)\n",
    "\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tp = cm[1, 1]\n",
    "fp = cm[0, 1]\n",
    "fn = cm[1, 0]\n",
    "tn = cm[0, 0]\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Confusion Matrix: \", cm)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Specificity: \", specificity)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "311b16e5-9fe3-45a4-b013-847d1d73e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3e07d2b3-07dd-4a60-8bdd-5cd2d7a3500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  1.084623862545468\n",
      "Root Mean Squared Error:  1.04\n",
      "Mean Absolute Error:  0.8387402733729703\n",
      "R - Squared:  -0.06813909168116017\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "x = np.random.rand(200, 1)\n",
    "y = 2 + 3 + x + np.random.randn(200, 1)   # True underlying relationship + random noise\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(f\"Root Mean Squared Error: {rmse: .2f}\")\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"R - Squared: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c47d55-bc36-4cbf-85cd-ea05964e7be3",
   "metadata": {},
   "source": [
    "### Exercise 1 - Build a linear regression with the dataset below and evaluate the model\r\n",
    "Instruction:\r\n",
    "1. Split the dataset into a training set (70% of the data) and a test set (30% of the data).\r\n",
    "2. Implement linear regression\r\n",
    "3. Train the linear regression model on the training set\r\n",
    "4. Evaluate the trained model's performance on the test set by calculating the Mean Squared Error, Root Mean Squared Error, Mean Absolute Error, R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c132a788-bbda-4753-ab55-db6f6d125e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "df = pd.DataFrame(np.column_stack([data['data'], data['target']]), columns = data['feature_names'] + ['target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "43c19366-b828-4512-9f30-632dc3981d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, 8].to_frame(), df['target'],\n",
    "                                                    test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "adbde64c-bee6-4850-9116-2aef15a858d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2f1785a4-14e7-47aa-9dfc-fac7d31f28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfd3684b-d7d9-4cd6-b0fd-e30d7e33884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  9.529851217218457e-30\n",
      "Root Mean Squared Error:  0.00\n",
      "Mean Absolute Error:  2.4079485893022765e-15\n",
      "R - Squared:  1.0\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(f\"Root Mean Squared Error: {rmse: .2f}\")\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"R - Squared: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b4b62-1b2f-4ee4-917b-985fc6698384",
   "metadata": {},
   "source": [
    "### Exercise 2 - Build a logistic regression with the dataset below and evaluate the model\r\n",
    "Instruction:\r\n",
    "1. Split the dataset into a training set (70% of the data) and a test set (30% of the data).\r\n",
    "2. Implement logistic regression\r\n",
    "3. Train the logistic regression model on the training set\r\n",
    "4. Evaluate the trained model's performance on the test set by calculating the accuracy, precision, recall, and F1 score.score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "05ec2b77-90c0-4ecd-8b5d-e924def6c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[ 637  424    7    1    0    0]\n",
      " [ 222 1963  303    4    0    4]\n",
      " [  16  567  833   56    0    8]\n",
      " [   5  104  378  102    1   36]\n",
      " [   2   18  110   59    0   51]\n",
      " [   2   24   60   28    0  167]]\n",
      "Accuracy:  0.8009858287122612\n",
      "Precision:  0.8223711772098868\n",
      "Recall:  0.8983981693363844\n",
      "Specificity:  0.6003770028275212\n",
      "F1 Score:  0.8587051618547681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "x = california_housing.data\n",
    "y = california_housing.target\n",
    "\n",
    "# Bin the target variable into categories\n",
    "bins = np.linspace(0, 5, 6) # Define bins for house price categories\n",
    "y_binned = np.digitize(y, bins)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_binned, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tp = cm[1, 1]\n",
    "fp = cm[0, 1]\n",
    "fn = cm[1, 0]\n",
    "tn = cm[0, 0]\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Confusion Matrix: \", cm)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Specificity: \", specificity)\n",
    "print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "de782467-e4b5-4ac4-9ca6-4c06ad972aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
